{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Embedding-Pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMUHNAOH2sGm/MVGv4rmO6+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stphnhng/482Project2/blob/master/Embedding_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lVjNK8shFKOC",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "# Install the latest Tensorflow version.\n",
        "!pip3 install --upgrade tensorflow-gpu\n",
        "# Install TF-Hub.\n",
        "!pip3 install tensorflow-hub\n",
        "!pip3 install seaborn\n",
        "\n",
        "#!mkdir encoder\n",
        "#!curl -Lo encoder/infersent1.pkl https://dl.fbaipublicfiles.com/infersent/infersent1.pkl\n",
        "#!curl -Lo encoder/infersent2.pkl https://dl.fbaipublicfiles.com/infersent/infersent2.pkl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zwty8Z6mAkdV",
        "outputId": "63016ce0-c591-445a-e4d0-d4252a98c29e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#@title Load the Universal Sentence Encoder's TF Hub module\n",
        "from absl import logging\n",
        "\n",
        "import json\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import seaborn as sns\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/4\", \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"]\n",
        "model = hub.load(module_url)\n",
        "print (\"module %s loaded\" % module_url)\n",
        "def embed(input):\n",
        "  return model(input)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "module https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieTu-Q3yfNKc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e4fdb556-7d52-4e38-bff5-a91e45246595"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqB_2id4gDE7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "1c95b78c-635a-446e-e495-be34f8f34e8b"
      },
      "source": [
        "import spacy\n",
        "!python -m spacy download en_core_web_lg"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_lg==2.1.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.1.0/en_core_web_lg-2.1.0.tar.gz (826.9MB)\n",
            "\u001b[K     |████████████████████████████████| 826.9MB 1.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.1.0-cp36-none-any.whl size=828255078 sha256=89978bd10d6f8ca0995941c771919c90fe63402b332e07b936adf5a8228a2e91\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-yejferr4/wheels/b4/d7/70/426d313a459f82ed5e06cc36a50e2bb2f0ec5cb31d8e0bdf09\n",
            "Successfully built en-core-web-lg\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-2.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfD0xxongHEO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import en_core_web_lg\n",
        "nlp = en_core_web_lg.load() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzQcEW3TnFpT",
        "colab_type": "code",
        "outputId": "e86c43e5-95f4-494b-a460-e135ef6d2de4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "suEn7bSQebWp",
        "colab": {}
      },
      "source": [
        "def read_json(file):\n",
        "  with open(file, 'r') as fp:\n",
        "    return json.loads(fp.read())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gGEkKEoBebWv",
        "colab": {}
      },
      "source": [
        "# Read in the data\n",
        "data = read_json(\"/content/drive/My Drive/data_wInfo.json\")\n",
        "qa = read_json(\"/content/drive/My Drive/cp_alexa_qa.json\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5t31uEmfY6p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = stopwords.words('english')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_8vVS3fRBzp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_content(data):\n",
        "  sentences = []\n",
        "  outputs = []\n",
        "  for section, content in data.items():\n",
        "    if content['content'] != '':\n",
        "      sent_toke = sent_tokenize(content['content'])\n",
        "      for index, sent in enumerate(sent_toke):\n",
        "        if sent == 'The W.K.':\n",
        "          sent_toke[index+1] = sent + sent_toke[index+1]\n",
        "        elif sent == 'Alumni include Abel Maldonado, Former California Lt.':\n",
        "          sent_toke[index+1] = sent + sent_toke[index+1]\n",
        "        else:\n",
        "          word_list = nltk.word_tokenize(sent)\n",
        "          output = [w for w in word_list if not w in stop_words]\n",
        "          outputs.append(' '.join(output))\n",
        "          sentences.append(sent)\n",
        "  return sentences, outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GSBph_kXd3-3",
        "colab": {}
      },
      "source": [
        "sentences, outputs = parse_content(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2Rh7HRljd3-6",
        "colab": {}
      },
      "source": [
        "sentences_embeddings = embed(sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7flqVMjGd3-9",
        "colab": {}
      },
      "source": [
        "outputs_embeddings = embed(outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V0wfD4MId3-_",
        "colab": {}
      },
      "source": [
        "def cos_sim(A, B):\n",
        "  return np.dot(A, B) / (np.linalg.norm(A) * np.linalg.norm(B))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDi6OpVMfcPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def match_infobox(query):\n",
        "    qa_infobox_qs = list(qa.items())[68:] # >68 are infobox questions\n",
        "    most_similar_ans = \"\"\n",
        "    most_similar_num = 0.0\n",
        "    for q,answer in qa_infobox_qs:\n",
        "        removed_stopwords = [word for word in nltk.word_tokenize(q) if word not in stop_words]\n",
        "        q = ' '.join(removed_stopwords)\n",
        "        sim = nlp(query).similarity(nlp(q))\n",
        "        print(q, sim)\n",
        "        if sim >= 0.75 and sim > most_similar_num:\n",
        "            print(sim, q)\n",
        "            most_similar_ans = answer\n",
        "            most_similar_num = sim\n",
        "    return most_similar_ans"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QnsPpSZ0d3_E",
        "colab": {}
      },
      "source": [
        "def find_sent_index(query, sentences_embeddings):\n",
        "  query_embedding = embed([query])\n",
        "  max_sim_index = 0\n",
        "  max_sim = -1\n",
        "  sim_list = []\n",
        "  for index, embedding in enumerate(sentences_embeddings):\n",
        "    current_sim = cos_sim(query_embedding, embedding)[0]\n",
        "    sim_list.append((index, current_sim))\n",
        "    if current_sim > max_sim:\n",
        "      max_sim = current_sim\n",
        "      max_sim_index = index\n",
        "  sim_list.sort(key=lambda x: x[1], reverse=True)\n",
        "  if max_sim < 0.5:\n",
        "    info_q = match_infobox(query)\n",
        "    print(\"max_sim < 0.5\")\n",
        "    if info_q != \"\":\n",
        "        return -1,[info_q] # if max index is -1, then answer is from QA\n",
        "  return max_sim_index, sim_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6dKxJfPeSFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index, scores = find_sent_index(\"What are the affiliations for Cal Poly?\", sentences_embeddings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfrHWRTlgzw1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}